{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09bc6eaa-3377-4226-911f-4155a0d8edc5",
   "metadata": {},
   "source": [
    "#2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154052d2-6a02-4215-b176-7a916bb65792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.2.1 Split training set and test set:\n",
      "\n",
      "Training set [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135]\n",
      "\n",
      "Test set [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('Classification iris.xlsx')\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "#Extract the first 70% index and concatenate to the data frame.\n",
    "for category in data['class'].unique():\n",
    "    category_data = data[data['class'] == category]\n",
    "    split_index = int(len(category_data) * 0.7)\n",
    "    train_data = pd.concat([train_data, category_data.iloc[:split_index]])\n",
    "    test_data = pd.concat([test_data, category_data.iloc[split_index:]])\n",
    "\n",
    "# extract the first column\n",
    "training_set_ids = [insid for insid in train_data.iloc[:, 0]]\n",
    "testing_set_ids = [insid for insid in test_data.iloc[:, 0]]\n",
    "    \n",
    "print(\"Q2.2.1 Split training set and test set:\")\n",
    "print(\"\\nTraining set\", training_set_ids)\n",
    "print(\"\\nTest set\", testing_set_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8c71b-3f0e-4172-b2f0-69550cd3551c",
   "metadata": {},
   "source": [
    "#2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c16ee51-42c1-4770-81f6-a28330373c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.2.2 Calculation using Standard SVM Model:\n",
      "total training error: 0.01904761904761909 total testing error: 0.0\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: [ 0.00945021  0.53765319 -0.82682922 -0.38216595]\n",
      "b: 0.774099177589861\n",
      "support vector indices: [23 24]\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.02857142857142858 , testing error: 0.0\n",
      "w: [-0.00708258  0.17885072 -0.53832399 -0.29218158]\n",
      "b: 1.5070188241897433\n",
      "support vector indices: [42 55 57 62 68]\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.02857142857142858 , testing error: 0.0\n",
      "w: [  3.64650338   5.176364    -7.42852538 -11.00241583]\n",
      "b: 17.570392115365593\n",
      "support vector indices: [ 76  96  97  99 103]\n",
      "Linear separable classes: ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "#---------------------------------------------data processing--------------------------------------------\n",
    "data = pd.read_excel('Classification iris.xlsx')\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "#Extract the first 70% index and concatenate to the data frame.\n",
    "for category in data['class'].unique():\n",
    "    category_data = data[data['class'] == category]\n",
    "    split_index = int(len(category_data) * 0.7)\n",
    "    train_data = pd.concat([train_data, category_data.iloc[:split_index]])\n",
    "    test_data = pd.concat([test_data, category_data.iloc[split_index:]])\n",
    "\n",
    "# extract X_train and y_train\n",
    "X_train = train_data.drop(columns=['instance_id', 'class'])\n",
    "y_train = train_data['class']\n",
    "\n",
    "# extract X_test and y_test\n",
    "X_test = test_data.drop(columns=['instance_id', 'class'])\n",
    "y_test = test_data['class']\n",
    "\n",
    "\n",
    "# Map class names into 0,1,2\n",
    "class_names = {\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2}\n",
    "y_train = y_train.map(class_names)\n",
    "y_test = y_test.map(class_names)\n",
    "\n",
    "#---------------------------------------------Training svm--------------------------------------------\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=1e5, decision_function_shape='ovr')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict values\n",
    "y_train_pred = svm_model.predict(X_train)\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "#Calculate train error and test error\n",
    "train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Q2.2.2 Calculation using Standard SVM Model:\")\n",
    "print(\"total training error:\", train_error, \"total testing error:\", test_error)\n",
    "\n",
    "#Extract w and b\n",
    "w = svm_model.coef_\n",
    "b = svm_model.intercept_\n",
    "\n",
    "# support vector indices and numebrs\n",
    "support_vector_indices = svm_model.support_\n",
    "support_vector_nums = svm_model.n_support_\n",
    "\n",
    "# create a list to store linear separable class\n",
    "linear_separable_classes = []\n",
    "\n",
    "for class_name, class_label in class_names.items():\n",
    "    # extract train data and test data for each class\n",
    "    class_train_data = train_data[train_data['class'] == class_name]\n",
    "    class_test_data = test_data[test_data['class'] == class_name]\n",
    "\n",
    "    # predict target y for train data and test data\n",
    "    class_y_train_pred = svm_model.predict(class_train_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "    class_y_test_pred = svm_model.predict(class_test_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "\n",
    "    # calculate train error and test error\n",
    "    class_train_error = 1 - accuracy_score(class_train_data['class'].map(class_names), class_y_train_pred)\n",
    "    class_test_error = 1 - accuracy_score(class_test_data['class'].map(class_names), class_y_test_pred)\n",
    "\n",
    "    # support vector indices for different class\n",
    "    if class_label == 0:\n",
    "        class_support_vector_indices = support_vector_indices[:support_vector_nums[0]]\n",
    "    elif class_label == 1:\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0]:support_vector_nums[0] + support_vector_nums[1]]\n",
    "    elif class_label == 2:\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0] + support_vector_nums[1]:]\n",
    "    \n",
    "    print(f\"\\nclass {class_name}:\")\n",
    "    print(\"training error:\", class_train_error, \", testing error:\", class_test_error)\n",
    "    print(\"w:\", w[class_label])\n",
    "    print(\"b:\", b[class_label])\n",
    "    print(\"support vector indices:\", class_support_vector_indices)\n",
    "\n",
    "    # judge whether linear separable by accuracy\n",
    "    if class_train_error < 0.05 and class_test_error < 0.05:\n",
    "        linear_separable_classes.append(class_name)\n",
    "\n",
    "print(\"Linear separable classes:\", linear_separable_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9564b1-2ee0-49da-93ba-790725ec3366",
   "metadata": {},
   "source": [
    "#2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d741d2b2-8fed-458a-b1ae-1fa8f21cf398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.2.3 Calculation using SVM with Slack Variables (C = 0.25 Ã— t, where t = 1, . . . , 4):\n",
      "--------------------------------------------------\n",
      "C= 0.25\n",
      "total training error: 0.04761904761904767 total testing error: 0.022222222222222254\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: [-0.16774186  0.41854832 -0.78709665 -0.31854832]\n",
      "b: 1.9412904435714369\n",
      "support vector indices: [23 24]\n",
      "slack variable: [ 3.03220571e-02 -5.02063441e-07]\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.02857142857142858 , testing error: 0.0\n",
      "w: [-0.00708258  0.17885072 -0.53832399 -0.29218158]\n",
      "b: 1.5070188241897433\n",
      "support vector indices: [35 37 39 40 41 42 48 51 53 55 57 58 61 62 63 64 68 69]\n",
      "slack variable: [1.9094139  2.06347367 1.95279866 1.83486388 1.94500734 1.16709484\n",
      " 1.9566948  1.85682179 2.00415191 2.0723281  2.16653455 1.91614355\n",
      " 2.03337007 2.19221094 1.8775399  1.24465556 2.26552259 1.85540528]\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.11428571428571432 , testing error: 0.06666666666666665\n",
      "w: [ 0.2036098   0.35471048 -1.49219548 -1.09064846]\n",
      "b: 6.979265887984469\n",
      "support vector indices: [ 71  76  80  81  83  85  86  89  91  93  96  97  99 103 104]\n",
      "slack variable: [1.564508   0.70525194 1.35369074 1.74078122 1.61565638 1.99968536\n",
      " 1.80338134 1.11566235 1.38038466 1.05519916 0.89086954 0.98950797\n",
      " 1.89038343 0.99097267 1.73966962]\n",
      "--------------------------------------------------\n",
      "C= 0.5\n",
      "total training error: 0.01904761904761909 total testing error: 0.022222222222222254\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: [-0.01268938  0.5069094  -0.80999736 -0.35882012]\n",
      "b: 0.9482249395776101\n",
      "support vector indices: [23 24]\n",
      "slack variable: [ 9.54226481e-05 -4.88951453e-05]\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.02857142857142858 , testing error: 0.0\n",
      "w: [-0.00708258  0.17885072 -0.53832399 -0.29218158]\n",
      "b: 1.5070188241897433\n",
      "support vector indices: [37 39 41 42 48 51 53 55 57 61 62 64 68 69]\n",
      "slack variable: [2.06347367 1.95279866 1.94500734 1.16709484 1.9566948  1.85682179\n",
      " 2.00415191 2.0723281  2.16653455 2.03337007 2.19221094 1.24465556\n",
      " 2.26552259 1.85540528]\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.02857142857142858 , testing error: 0.06666666666666665\n",
      "w: [ 0.47229269  0.57470117 -1.88760999 -1.38942081]\n",
      "b: 7.08831681344711\n",
      "support vector indices: [ 71  76  80  81  83  86  89  91  93  96  97  99 103]\n",
      "slack variable: [1.88740289 1.0169564  1.4083895  1.98154928 1.99975348 2.00048957\n",
      " 1.33576562 1.6858114  1.13479247 0.93579062 1.05684066 1.95828352\n",
      " 1.0380181 ]\n",
      "--------------------------------------------------\n",
      "C= 0.75\n",
      "total training error: 0.01904761904761909 total testing error: 0.022222222222222254\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: [ 0.00945021  0.53765319 -0.82682922 -0.38216595]\n",
      "b: 0.774099177589861\n",
      "support vector indices: [23 24]\n",
      "slack variable: [ 1.41894397e-04 -7.23034453e-05]\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.02857142857142858 , testing error: 0.0\n",
      "w: [-0.00708258  0.17885072 -0.53832399 -0.29218158]\n",
      "b: 1.5070188241897433\n",
      "support vector indices: [37 41 42 48 51 53 55 57 61 62 68 69]\n",
      "slack variable: [2.06347367 1.94500734 1.16709484 1.9566948  1.85682179 2.00415191\n",
      " 2.0723281  2.16653455 2.03337007 2.19221094 2.26552259 1.85540528]\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.02857142857142858 , testing error: 0.06666666666666665\n",
      "w: [ 0.5194272   0.76823194 -1.94232407 -1.59321649]\n",
      "b: 6.870204326289063\n",
      "support vector indices: [ 71  76  80  86  89  91  93  96  97  99 103]\n",
      "slack variable: [1.97585576 1.11294889 1.38746239 1.99939511 1.42456728 1.77377484\n",
      " 1.16835569 0.94924281 1.04177155 1.89984999 1.00203236]\n",
      "--------------------------------------------------\n",
      "C= 1.0\n",
      "total training error: 0.01904761904761909 total testing error: 0.022222222222222254\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: [ 0.00945021  0.53765319 -0.82682922 -0.38216595]\n",
      "b: 0.774099177589861\n",
      "support vector indices: [23 24]\n",
      "slack variable: [ 1.41894397e-04 -7.23034453e-05]\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.02857142857142858 , testing error: 0.0\n",
      "w: [-0.00708258  0.17885072 -0.53832399 -0.29218158]\n",
      "b: 1.5070188241897433\n",
      "support vector indices: [37 41 42 48 51 53 55 57 61 62 68 69]\n",
      "slack variable: [2.06347367 1.94500734 1.16709484 1.9566948  1.85682179 2.00415191\n",
      " 2.0723281  2.16653455 2.03337007 2.19221094 2.26552259 1.85540528]\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.02857142857142858 , testing error: 0.06666666666666665\n",
      "w: [ 0.48530399  0.75633921 -1.99689792 -1.68000193]\n",
      "b: 7.519499025931048\n",
      "support vector indices: [ 71  76  80  89  91  93  96  97  99 103]\n",
      "slack variable: [1.99980502 1.05370732 1.44992282 1.40922327 1.78985251 1.18977325\n",
      " 0.96297994 1.05993229 1.98730564 1.00951834]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "#---------------------------------------------data processing--------------------------------------------\n",
    "data = pd.read_excel('Classification iris.xlsx')\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "#Extract the first 70% index and concatenate to the data frame.\n",
    "for category in data['class'].unique():\n",
    "    category_data = data[data['class'] == category]\n",
    "    split_index = int(len(category_data) * 0.7)\n",
    "    train_data = pd.concat([train_data, category_data.iloc[:split_index]])\n",
    "    test_data = pd.concat([test_data, category_data.iloc[split_index:]])\n",
    "\n",
    "# extract X_train and y_train\n",
    "X_train = train_data.drop(columns=['instance_id', 'class'])\n",
    "y_train = train_data['class']\n",
    "\n",
    "# extract X_test and y_test\n",
    "X_test = test_data.drop(columns=['instance_id', 'class'])\n",
    "y_test = test_data['class']\n",
    "\n",
    "# Map class names into 0,1,2\n",
    "class_names = {\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2}\n",
    "y_train = y_train.map(class_names)\n",
    "y_test = y_test.map(class_names)\n",
    "\n",
    "print(\"Q2.2.3 Calculation using SVM with Slack Variables (C = 0.25 Ã— t, where t = 1, . . . , 4):\")\n",
    "\n",
    "#---------------------------------------------Training svm--------------------------------------------\n",
    "for t in range(1,5):\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"C=\", 0.25*t)\n",
    "\n",
    "    # train svm\n",
    "    svm_model = SVC(kernel='linear', C=0.25*t, decision_function_shape='ovr')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # predict values\n",
    "    y_train_pred = svm_model.predict(X_train)\n",
    "    y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "    # train error and test error\n",
    "    train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "    test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"total training error:\", train_error, \"total testing error:\", test_error)\n",
    "\n",
    "    # w and b\n",
    "    w = svm_model.coef_\n",
    "    b = svm_model.intercept_\n",
    "\n",
    "    # support vectors\n",
    "    support_vector_indices = svm_model.support_\n",
    "    support_vector_nums = svm_model.n_support_\n",
    "        \n",
    "    for class_name, class_label in class_names.items():\n",
    "        # extract class train data and test data\n",
    "        class_train_data = train_data[train_data['class'] == class_name]\n",
    "        class_test_data = test_data[test_data['class'] == class_name]\n",
    "\n",
    "        # predict values\n",
    "        class_y_train_pred = svm_model.predict(class_train_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "        class_y_test_pred = svm_model.predict(class_test_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "\n",
    "        # train error and test error for class\n",
    "        class_train_error = 1 - accuracy_score(class_train_data['class'].map(class_names), class_y_train_pred)\n",
    "        class_test_error = 1 - accuracy_score(class_test_data['class'].map(class_names), class_y_test_pred)\n",
    "\n",
    "        # support vector indices\n",
    "        if class_label == 0:\n",
    "            class_support_vector_indices = support_vector_indices[:support_vector_nums[0]]\n",
    "        elif class_label == 1:\n",
    "            class_support_vector_indices = support_vector_indices[support_vector_nums[0]:support_vector_nums[0] + support_vector_nums[1]]\n",
    "        elif class_label == 2:\n",
    "            class_support_vector_indices = support_vector_indices[support_vector_nums[0] + support_vector_nums[1]:]\n",
    "\n",
    "        # since y_train consists of 0,1,2, we need to convert it to binary array, then calculate slack variable.\n",
    "        support_vectors = X_train.iloc[class_support_vector_indices]\n",
    "        binary_y_train = np.where(y_train == class_label, 1, -1)\n",
    "        slack_variables = 1 - binary_y_train[class_support_vector_indices] * (np.dot(support_vectors, w[class_label]) + b[class_label])\n",
    "        \n",
    "        print(f\"\\nclass {class_name}:\")\n",
    "        print(\"training error:\", class_train_error, \", testing error:\", class_test_error)\n",
    "        print(\"w:\", w[class_label])\n",
    "        print(\"b:\", b[class_label])\n",
    "        print(\"support vector indices:\", class_support_vector_indices)\n",
    "        print(\"slack variable:\", slack_variables)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a61a8-e208-4d77-9e58-cea55f7eb1bf",
   "metadata": {},
   "source": [
    "#2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e8a364-b20e-4f03-bd39-2ec4d87c1b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2.2.4 Calculation using SVM with Kernel Functions:\n",
      "------------------------------------------\n",
      "(a) 2nd-order Polynomial Kernel,\n",
      "total training error: 0.00952380952380949 total testing error: 0.0\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: \n",
      "b: \n",
      "support vector indices: [23 24]\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.02857142857142858 , testing error: 0.0\n",
      "w: \n",
      "b: \n",
      "support vector indices: [42 55 57 58 62 68]\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: \n",
      "b: \n",
      "support vector indices: [ 76  89  96  97 103]\n",
      "------------------------------------------\n",
      "(b) 3nd-order Polynomial Kernel,\n",
      "total training error: 0.0 total testing error: 0.0\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: \n",
      "b: \n",
      "support vector indices: [23 24]\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: \n",
      "b: \n",
      "support vector indices: [42 55 57 58 68]\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: \n",
      "b: \n",
      "support vector indices: [ 76  89  93  96 103]\n",
      "------------------------------------------\n",
      "(c) Radial Basis Function Kernel with Ïƒ = 1,\n",
      "total training error: 0.0 total testing error: 0.06666666666666665\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: \n",
      "b: \n",
      "support vector indices: [ 8 13 14 15 24 25]\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.0 , testing error: 0.0\n",
      "w: \n",
      "b: \n",
      "support vector indices: [35 41 42 45 47 53 55 57 62 68 69]\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.0 , testing error: 0.19999999999999996\n",
      "w: \n",
      "b: \n",
      "support vector indices: [ 70  71  76  79  80  84  88  89  96  97  99 100 101 103 104]\n",
      "------------------------------------------\n",
      "(d) Sigmoidal Kernel with Ïƒ = 1,\n",
      "total training error: 0.3047619047619048 , total testing error: 0.2222222222222222\n",
      "\n",
      "class Iris-setosa:\n",
      "training error: 0.0 , testing error: 0.06666666666666665\n",
      "w:\n",
      "b:\n",
      "support vector indices: [8]\n",
      "\n",
      "class Iris-versicolor:\n",
      "training error: 0.4571428571428572 , testing error: 0.19999999999999996\n",
      "w:\n",
      "b:\n",
      "support vector indices: [35 36 37 39 41 42 43 48 50 55 57 59 60 61 62 63 68]\n",
      "\n",
      "class Iris-virginica:\n",
      "training error: 0.4571428571428572 , testing error: 0.4\n",
      "w:\n",
      "b:\n",
      "support vector indices: [ 72  75  76  77  79  82  87  88  89  90  92  94  95  99 100 101]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#---------------------------------------------data processing--------------------------------------------\n",
    "data = pd.read_excel('Classification iris.xlsx')\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "#Extract the first 70% index and concatenate to the data frame.\n",
    "for category in data['class'].unique():\n",
    "    category_data = data[data['class'] == category]\n",
    "    split_index = int(len(category_data) * 0.7)\n",
    "    train_data = pd.concat([train_data, category_data.iloc[:split_index]])\n",
    "    test_data = pd.concat([test_data, category_data.iloc[split_index:]])\n",
    "\n",
    "# extract X_train and y_train\n",
    "X_train = train_data.drop(columns=['instance_id', 'class'])\n",
    "y_train = train_data['class']\n",
    "\n",
    "# extract X_test and y_test\n",
    "X_test = test_data.drop(columns=['instance_id', 'class'])\n",
    "y_test = test_data['class']\n",
    "\n",
    "# Map class names into 0,1,2\n",
    "class_names = {\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2}\n",
    "y_train = y_train.map(class_names)\n",
    "y_test = y_test.map(class_names)\n",
    "\n",
    "print(\"Q2.2.4 Calculation using SVM with Kernel Functions:\")\n",
    "\n",
    "#---------------------------------------------Training svm--------------------------------------------    \n",
    "\n",
    "\n",
    "#---------------------------2nd-poly--------------------------------\n",
    "\n",
    "print(\"------------------------------------------\")\n",
    "print(\"(a) 2nd-order Polynomial Kernel,\")\n",
    "svm_model_p2 = SVC(kernel='poly', degree=2, C=1e5, decision_function_shape='ovr')\n",
    "svm_model_p2.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svm_model_p2.predict(X_train)\n",
    "y_test_pred = svm_model_p2.predict(X_test)\n",
    "\n",
    "train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"total training error:\", train_error, \"total testing error:\", test_error)\n",
    "\n",
    "# w = svm_model.coef_\n",
    "# b = svm_model.intercept_\n",
    "\n",
    "# extratc support vector indices and numbers\n",
    "support_vector_indices = svm_model_p2.support_\n",
    "support_vector_nums = svm_model_p2.n_support_\n",
    "\n",
    "\n",
    "for class_name, class_label in class_names.items():\n",
    "    # extract train data and test data for each class\n",
    "    class_train_data = train_data[train_data['class'] == class_name]\n",
    "    class_test_data = test_data[test_data['class'] == class_name]\n",
    "\n",
    "    # predict target y for train data and test data\n",
    "    class_y_train_pred = svm_model_p2.predict(class_train_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "    class_y_test_pred = svm_model_p2.predict(class_test_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "\n",
    "    # calculate train error and test error\n",
    "    class_train_error = 1 - accuracy_score(class_train_data['class'].map(class_names), class_y_train_pred)\n",
    "    class_test_error = 1 - accuracy_score(class_test_data['class'].map(class_names), class_y_test_pred)\n",
    "\n",
    "    # extract support vecctor indices for each class based on class label\n",
    "    if class_label == 0:\n",
    "        class_support_vector_indices = support_vector_indices[:support_vector_nums[0]]\n",
    "    elif class_label == 1:\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0]:support_vector_nums[0] + support_vector_nums[1]]\n",
    "    elif class_label == 2:\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0] + support_vector_nums[1]:]\n",
    "    \n",
    "    \n",
    "    print(f\"\\nclass {class_name}:\")\n",
    "    print(\"training error:\", class_train_error, \", testing error:\", class_test_error)\n",
    "    print(\"w: \")\n",
    "    print(\"b: \")\n",
    "    print(\"support vector indices:\", class_support_vector_indices)\n",
    "\n",
    "#---------------------------3nd-poly--------------------------------\n",
    "\n",
    "print(\"------------------------------------------\")\n",
    "print(\"(b) 3nd-order Polynomial Kernel,\")\n",
    "\n",
    "svm_model_p3 = SVC(kernel='poly', degree=3, C=1e5, decision_function_shape='ovr')\n",
    "svm_model_p3.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svm_model_p3.predict(X_train)\n",
    "y_test_pred = svm_model_p3.predict(X_test)\n",
    "\n",
    "train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"total training error:\", train_error, \"total testing error:\", test_error)\n",
    "\n",
    "# w = svm_model.coef_\n",
    "# b = svm_model.intercept_\n",
    "\n",
    "# extratc support vector indices and numbers\n",
    "support_vector_indices = svm_model_p3.support_\n",
    "support_vector_nums = svm_model_p3.n_support_\n",
    "\n",
    "for class_name, class_label in class_names.items():\n",
    "    # extract train data and test data for each class\n",
    "    class_train_data = train_data[train_data['class'] == class_name]\n",
    "    class_test_data = test_data[test_data['class'] == class_name]\n",
    "\n",
    "    # predict target y for train data and test data\n",
    "    class_y_train_pred = svm_model_p3.predict(class_train_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "    class_y_test_pred = svm_model_p3.predict(class_test_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "\n",
    "    # calculate train error and test error\n",
    "    class_train_error = 1 - accuracy_score(class_train_data['class'].map(class_names), class_y_train_pred)\n",
    "    class_test_error = 1 - accuracy_score(class_test_data['class'].map(class_names), class_y_test_pred)\n",
    "\n",
    "    # extract support vecctor indices for each class based on class label\n",
    "    if class_label == 0:\n",
    "        class_support_vector_indices = support_vector_indices[:support_vector_nums[0]]\n",
    "    elif class_label == 1:\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0]:support_vector_nums[0] + support_vector_nums[1]]\n",
    "    elif class_label == 2:\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0] + support_vector_nums[1]:]\n",
    "    \n",
    "    \n",
    "    print(f\"\\nclass {class_name}:\")\n",
    "    print(\"training error:\", class_train_error, \", testing error:\", class_test_error)\n",
    "    print(\"w: \")\n",
    "    print(\"b: \")\n",
    "    print(\"support vector indices:\", class_support_vector_indices)\n",
    "\n",
    "\n",
    "#---------------------------rbf--------------------------------\n",
    "\n",
    "print(\"------------------------------------------\")\n",
    "print(\"(c) Radial Basis Function Kernel with Ïƒ = 1,\")\n",
    "\n",
    "svm_model_rbf = SVC(kernel='rbf', gamma=0.5, C=1e5, decision_function_shape='ovr')\n",
    "svm_model_rbf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svm_model_rbf.predict(X_train)\n",
    "y_test_pred = svm_model_rbf.predict(X_test)\n",
    "\n",
    "train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"total training error:\", train_error, \"total testing error:\", test_error)\n",
    "\n",
    "# w = svm_model.coef_\n",
    "# b = svm_model.intercept_\n",
    "\n",
    "# extratc support vector indices and numbers\n",
    "support_vector_indices = svm_model_rbf.support_\n",
    "support_vector_nums = svm_model_rbf.n_support_\n",
    "\n",
    "\n",
    "for class_name, class_label in class_names.items():\n",
    "    # extract train data and test data for each class\n",
    "    class_train_data = train_data[train_data['class'] == class_name]\n",
    "    class_test_data = test_data[test_data['class'] == class_name]\n",
    "\n",
    "    # predict target y for train data and test data\n",
    "    class_y_train_pred = svm_model_rbf.predict(class_train_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "    class_y_test_pred = svm_model_rbf.predict(class_test_data[['sepal length', 'sepal width', 'petal length', 'petal width']])\n",
    "\n",
    "    # calculate train error and test error\n",
    "    class_train_error = 1 - accuracy_score(class_train_data['class'].map(class_names), class_y_train_pred)\n",
    "    class_test_error = 1 - accuracy_score(class_test_data['class'].map(class_names), class_y_test_pred)\n",
    "\n",
    "    # extract support vecctor indices for each class based on class label\n",
    "    if class_label == 0:\n",
    "        class_support_vector_indices = support_vector_indices[:support_vector_nums[0]]\n",
    "    elif class_label == 1:\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0]:support_vector_nums[0] + support_vector_nums[1]]\n",
    "    elif class_label == 2:\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0] + support_vector_nums[1]:]\n",
    "    \n",
    "    \n",
    "    print(f\"\\nclass {class_name}:\")\n",
    "    print(\"training error:\", class_train_error, \", testing error:\", class_test_error)\n",
    "    print(\"w: \")\n",
    "    print(\"b: \")\n",
    "    print(\"support vector indices:\", class_support_vector_indices)\n",
    "\n",
    "#---------------------------sigmoid--------------------------------\n",
    "\n",
    "print(\"------------------------------------------\")\n",
    "print(\"(d) Sigmoidal Kernel with Ïƒ = 1,\")\n",
    "\n",
    "# train data and test data\n",
    "X_train = train_data.drop(columns=['instance_id', 'class'])\n",
    "y_train = train_data['class']\n",
    "X_test = test_data.drop(columns=['instance_id', 'class'])\n",
    "y_test = test_data['class']\n",
    "\n",
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# train svm\n",
    "svm_model = SVC(kernel='sigmoid', C=1e5, gamma=0.5, decision_function_shape='ovr')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# claculate training error, test error\n",
    "y_train_pred = svm_model.predict(X_train)\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"total training error:\", train_error, \", total testing error:\", test_error)\n",
    "\n",
    "\n",
    "\n",
    "support_vector_indices = svm_model.support_\n",
    "support_vector_nums = svm_model.n_support_\n",
    "\n",
    "\n",
    "for class_name in data['class'].unique():\n",
    "    class_indices_train = (y_train == class_name)\n",
    "    class_indices_test = (y_test == class_name)\n",
    "    \n",
    "    y_train_class_pred = y_train_pred[class_indices_train]\n",
    "    y_test_class_pred = y_test_pred[class_indices_test]\n",
    "    \n",
    "    train_class_error = 1 - accuracy_score(y_train[class_indices_train], y_train_class_pred)\n",
    "    test_class_error = 1 - accuracy_score(y_test[class_indices_test], y_test_class_pred)\n",
    "    \n",
    "    # support vector indices\n",
    "    if class_name == \"Iris-setosa\":\n",
    "        class_support_vector_indices = support_vector_indices[:support_vector_nums[0]]\n",
    "    elif class_name == \"Iris-versicolor\":\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0]:support_vector_nums[0] + support_vector_nums[1]]\n",
    "    elif class_name == \"Iris-virginica\":\n",
    "        class_support_vector_indices = support_vector_indices[support_vector_nums[0] + support_vector_nums[1]:]\n",
    "\n",
    "    # since y_train consists of 0,1,2, we need to convert it to binary array, then calculate slack variable.\n",
    "    support_vectors = X_train[class_support_vector_indices]\n",
    "    \n",
    "    print(f\"\\nclass {class_name}:\")\n",
    "    print(\"training error:\", train_class_error, \", testing error:\", test_class_error)\n",
    "    print(\"w:\")\n",
    "    print(\"b:\")\n",
    "    print(\"support vector indices:\", class_support_vector_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e764b-7794-4566-9a3e-e3d5e02195cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
